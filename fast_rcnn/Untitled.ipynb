{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'roidb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-454100f4b7dd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcfg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mroidb\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgdl_roidb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mroi_data_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mroidb\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mrdl_roidb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mroi_data_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRoIDataLayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: No module named 'roidb'"
     ]
    }
   ],
   "source": [
    "# %load train.py\n",
    "# --------------------------------------------------------\n",
    "# Fast R-CNN\n",
    "# Copyright (c) 2015 Microsoft\n",
    "# Licensed under The MIT License [see LICENSE for details]\n",
    "# Written by Ross Girshick\n",
    "# --------------------------------------------------------\n",
    "\n",
    "\"\"\"Train a Fast R-CNN network.\"\"\"\n",
    "\n",
    "from config import cfg\n",
    "import gt_data_layer.roidb as gdl_roidb\n",
    "import roi_data_layer.roidb as rdl_roidb\n",
    "from roi_data_layer.layer import RoIDataLayer\n",
    "from utils.timer import Timer\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "from tensorflow.python.client import timeline\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SolverWrapper(object):\n",
    "    \"\"\"A simple wrapper around Caffe's solver.\n",
    "    This wrapper gives us control over he snapshotting process, which we\n",
    "    use to unnormalize the learned bounding-box regression weights.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sess, saver, network, imdb, roidb, output_dir, pretrained_model=None):\n",
    "        \"\"\"Initialize the SolverWrapper.\"\"\"\n",
    "        self.net = network\n",
    "        self.imdb = imdb\n",
    "        self.roidb = roidb\n",
    "        self.output_dir = output_dir\n",
    "        self.pretrained_model = pretrained_model\n",
    "\n",
    "        print 'Computing bounding-box regression targets...'\n",
    "        if cfg.TRAIN.BBOX_REG:\n",
    "            self.bbox_means, self.bbox_stds = rdl_roidb.add_bbox_regression_targets(roidb)\n",
    "        print 'done'\n",
    "\n",
    "        # For checkpoint\n",
    "        self.saver = saver\n",
    "\n",
    "    def snapshot(self, sess, iter):\n",
    "        \"\"\"Take a snapshot of the network after unnormalizing the learned\n",
    "        bounding-box regression weights. This enables easy use at test-time.\n",
    "        \"\"\"\n",
    "        net = self.net\n",
    "\n",
    "        if cfg.TRAIN.BBOX_REG and net.layers.has_key('bbox_pred'):\n",
    "            # save original values\n",
    "            with tf.variable_scope('bbox_pred', reuse=True):\n",
    "                weights = tf.get_variable(\"weights\")\n",
    "                biases = tf.get_variable(\"biases\")\n",
    "\n",
    "            orig_0 = weights.eval()\n",
    "            orig_1 = biases.eval()\n",
    "\n",
    "            # scale and shift with bbox reg unnormalization; then save snapshot\n",
    "            weights_shape = weights.get_shape().as_list()\n",
    "            sess.run(net.bbox_weights_assign, feed_dict={net.bbox_weights: orig_0 * np.tile(self.bbox_stds, (weights_shape[0], 1))})\n",
    "            sess.run(net.bbox_bias_assign, feed_dict={net.bbox_biases: orig_1 * self.bbox_stds + self.bbox_means})\n",
    "\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "        infix = ('_' + cfg.TRAIN.SNAPSHOT_INFIX\n",
    "                 if cfg.TRAIN.SNAPSHOT_INFIX != '' else '')\n",
    "        filename = (cfg.TRAIN.SNAPSHOT_PREFIX + infix +\n",
    "                    '_iter_{:d}'.format(iter+1) + '.ckpt')\n",
    "        filename = os.path.join(self.output_dir, filename)\n",
    "\n",
    "        self.saver.save(sess, filename)\n",
    "        print 'Wrote snapshot to: {:s}'.format(filename)\n",
    "\n",
    "        if cfg.TRAIN.BBOX_REG and net.layers.has_key('bbox_pred'):\n",
    "            with tf.variable_scope('bbox_pred', reuse=True):\n",
    "                # restore net to original state\n",
    "                sess.run(net.bbox_weights_assign, feed_dict={net.bbox_weights: orig_0})\n",
    "                sess.run(net.bbox_bias_assign, feed_dict={net.bbox_biases: orig_1})\n",
    "\n",
    "    def _modified_smooth_l1(self, sigma, bbox_pred, bbox_targets, bbox_inside_weights, bbox_outside_weights):\n",
    "        \"\"\"\n",
    "            ResultLoss = outside_weights * SmoothL1(inside_weights * (bbox_pred - bbox_targets))\n",
    "            SmoothL1(x) = 0.5 * (sigma * x)^2,    if |x| < 1 / sigma^2\n",
    "                          |x| - 0.5 / sigma^2,    otherwise\n",
    "        \"\"\"\n",
    "        sigma2 = sigma * sigma\n",
    "\n",
    "        inside_mul = tf.multiply(bbox_inside_weights, tf.subtract(bbox_pred, bbox_targets))\n",
    "\n",
    "        smooth_l1_sign = tf.cast(tf.less(tf.abs(inside_mul), 1.0 / sigma2), tf.float32)\n",
    "        #smooth_l1_option1 = tf.matmul(tf.matmul(inside_mul, inside_mul), 0.5 * sigma2)\n",
    "\n",
    "        smooth_l1_option1 = tf.multiply(tf.multiply(inside_mul, inside_mul), 0.5 * sigma2)\n",
    "\n",
    "        smooth_l1_option2 = tf.subtract(tf.abs(inside_mul), 0.5 / sigma2)\n",
    "        smooth_l1_result = tf.add(tf.multiply(smooth_l1_option1, smooth_l1_sign),\n",
    "                                  tf.multiply(smooth_l1_option2, tf.abs(tf.subtract(smooth_l1_sign, 1.0))))\n",
    "\n",
    "        outside_mul = tf.multiply(bbox_outside_weights, smooth_l1_result)\n",
    "\n",
    "        return outside_mul\n",
    "\n",
    "\n",
    "    def train_model(self, sess, max_iters):\n",
    "        \"\"\"Network training loop.\"\"\"\n",
    "\n",
    "        data_layer = get_data_layer(self.roidb, self.imdb.num_classes)\n",
    "\n",
    "        # RPN\n",
    "        # classification loss\n",
    "        rpn_cls_score = tf.reshape(self.net.get_output('rpn_cls_score_reshape'),[-1,2])\n",
    "        rpn_label = tf.reshape(self.net.get_output('rpn-data')[0],[-1])\n",
    "        rpn_cls_score = tf.reshape(tf.gather(rpn_cls_score,tf.where(tf.not_equal(rpn_label,-1))),[-1,2])\n",
    "        rpn_label = tf.reshape(tf.gather(rpn_label,tf.where(tf.not_equal(rpn_label,-1))),[-1])\n",
    "        rpn_cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=rpn_cls_score, labels=rpn_label))\n",
    "\n",
    "        # bounding box regression L1 loss\n",
    "        rpn_bbox_pred = self.net.get_output('rpn_bbox_pred')\n",
    "        rpn_bbox_targets = tf.transpose(self.net.get_output('rpn-data')[1],[0,2,3,1])\n",
    "        rpn_bbox_inside_weights = tf.transpose(self.net.get_output('rpn-data')[2],[0,2,3,1])\n",
    "        rpn_bbox_outside_weights = tf.transpose(self.net.get_output('rpn-data')[3],[0,2,3,1])\n",
    "\n",
    "        rpn_smooth_l1 = self._modified_smooth_l1(3.0, rpn_bbox_pred, rpn_bbox_targets, rpn_bbox_inside_weights, rpn_bbox_outside_weights)\n",
    "        rpn_loss_box = tf.multiply(tf.reduce_mean(tf.reduce_sum(rpn_smooth_l1, reduction_indices=[1, 2, 3])), 10)\n",
    " \n",
    "        # R-CNN\n",
    "        # classification loss\n",
    "        cls_score = self.net.get_output('cls_score')\n",
    "        label = tf.reshape(self.net.get_output('roi-data')[1],[-1])\n",
    "        cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(logits=cls_score, labels=label))\n",
    "\n",
    "        # bounding box regression L1 loss\n",
    "        bbox_pred = self.net.get_output('bbox_pred')\n",
    "        bbox_targets = self.net.get_output('roi-data')[2]\n",
    "        bbox_inside_weights = self.net.get_output('roi-data')[3]\n",
    "        bbox_outside_weights = self.net.get_output('roi-data')[4]\n",
    "\n",
    "        smooth_l1 = self._modified_smooth_l1(1.0, bbox_pred, bbox_targets, bbox_inside_weights, bbox_outside_weights)\n",
    "        loss_box = tf.reduce_mean(tf.reduce_sum(smooth_l1, reduction_indices=[1]))\n",
    "\n",
    "        # final loss\n",
    "        loss = cross_entropy + loss_box + rpn_cross_entropy + rpn_loss_box\n",
    "\n",
    "        # optimizer and learning rate\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        lr = tf.train.exponential_decay(cfg.TRAIN.LEARNING_RATE, global_step,\n",
    "                                        cfg.TRAIN.STEPSIZE, 0.1, staircase=True)\n",
    "        momentum = cfg.TRAIN.MOMENTUM\n",
    "        train_op = tf.train.MomentumOptimizer(lr, momentum).minimize(loss, global_step=global_step)\n",
    "\n",
    "        # iintialize variables\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        if self.pretrained_model is not None:\n",
    "            print ('Loading pretrained model '\n",
    "                   'weights from {:s}').format(self.pretrained_model)\n",
    "            self.net.load(self.pretrained_model, sess, self.saver, True)\n",
    "\n",
    "        last_snapshot_iter = -1\n",
    "        timer = Timer()\n",
    "        for iter in range(max_iters):\n",
    "            # get one batch\n",
    "            blobs = data_layer.forward()\n",
    "\n",
    "            # Make one SGD update\n",
    "            feed_dict={self.net.data: blobs['data'], self.net.im_info: blobs['im_info'], self.net.keep_prob: 0.5, \\\n",
    "                           self.net.gt_boxes: blobs['gt_boxes']}\n",
    "\n",
    "            run_options = None\n",
    "            run_metadata = None\n",
    "            if cfg.TRAIN.DEBUG_TIMELINE:\n",
    "                run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "                run_metadata = tf.RunMetadata()\n",
    "\n",
    "            timer.tic()\n",
    "\n",
    "            rpn_loss_cls_value, rpn_loss_box_value,loss_cls_value, loss_box_value, _ = sess.run([rpn_cross_entropy, rpn_loss_box, cross_entropy, loss_box, train_op],\n",
    "                                                                                                feed_dict=feed_dict,\n",
    "                                                                                                options=run_options,\n",
    "                                                                                                run_metadata=run_metadata)\n",
    "\n",
    "            timer.toc()\n",
    "\n",
    "            if cfg.TRAIN.DEBUG_TIMELINE:\n",
    "                trace = timeline.Timeline(step_stats=run_metadata.step_stats)\n",
    "                trace_file = open(str(long(time.time() * 1000)) + '-train-timeline.ctf.json', 'w')\n",
    "                trace_file.write(trace.generate_chrome_trace_format(show_memory=False))\n",
    "                trace_file.close()\n",
    "\n",
    "            if (iter+1) % (cfg.TRAIN.DISPLAY) == 0:\n",
    "                print 'iter: %d / %d, total loss: %.4f, rpn_loss_cls: %.4f, rpn_loss_box: %.4f, loss_cls: %.4f, loss_box: %.4f, lr: %f'%\\\n",
    "                        (iter+1, max_iters, rpn_loss_cls_value + rpn_loss_box_value + loss_cls_value + loss_box_value ,rpn_loss_cls_value, rpn_loss_box_value,loss_cls_value, loss_box_value, lr.eval())\n",
    "                print 'speed: {:.3f}s / iter'.format(timer.average_time)\n",
    "\n",
    "            if (iter+1) % cfg.TRAIN.SNAPSHOT_ITERS == 0:\n",
    "                last_snapshot_iter = iter\n",
    "                self.snapshot(sess, iter)\n",
    "\n",
    "        if last_snapshot_iter != iter:\n",
    "            self.snapshot(sess, iter)\n",
    "\n",
    "def get_training_roidb(imdb):\n",
    "    \"\"\"Returns a roidb (Region of Interest database) for use in training.\"\"\"\n",
    "    if cfg.TRAIN.USE_FLIPPED:\n",
    "        print 'Appending horizontally-flipped training examples...'\n",
    "        imdb.append_flipped_images()\n",
    "        print 'done'\n",
    "\n",
    "    print 'Preparing training data...'\n",
    "    if cfg.TRAIN.HAS_RPN:\n",
    "        if cfg.IS_MULTISCALE:\n",
    "            gdl_roidb.prepare_roidb(imdb)\n",
    "        else:\n",
    "            rdl_roidb.prepare_roidb(imdb)\n",
    "    else:\n",
    "        rdl_roidb.prepare_roidb(imdb)\n",
    "    print 'done'\n",
    "\n",
    "    return imdb.roidb\n",
    "\n",
    "\n",
    "def get_data_layer(roidb, num_classes):\n",
    "    \"\"\"return a data layer.\"\"\"\n",
    "    if cfg.TRAIN.HAS_RPN:\n",
    "        if cfg.IS_MULTISCALE:\n",
    "            layer = GtDataLayer(roidb)\n",
    "        else:\n",
    "            layer = RoIDataLayer(roidb, num_classes)\n",
    "    else:\n",
    "        layer = RoIDataLayer(roidb, num_classes)\n",
    "\n",
    "    return layer\n",
    "\n",
    "def filter_roidb(roidb):\n",
    "    \"\"\"Remove roidb entries that have no usable RoIs.\"\"\"\n",
    "\n",
    "    def is_valid(entry):\n",
    "        # Valid images have:\n",
    "        #   (1) At least one foreground RoI OR\n",
    "        #   (2) At least one background RoI\n",
    "        overlaps = entry['max_overlaps']\n",
    "        # find boxes with sufficient overlap\n",
    "        fg_inds = np.where(overlaps >= cfg.TRAIN.FG_THRESH)[0]\n",
    "        # Select background RoIs as those within [BG_THRESH_LO, BG_THRESH_HI)\n",
    "        bg_inds = np.where((overlaps < cfg.TRAIN.BG_THRESH_HI) &\n",
    "                           (overlaps >= cfg.TRAIN.BG_THRESH_LO))[0]\n",
    "        # image is only valid if such boxes exist\n",
    "        valid = len(fg_inds) > 0 or len(bg_inds) > 0\n",
    "        return valid\n",
    "\n",
    "    num = len(roidb)\n",
    "    filtered_roidb = [entry for entry in roidb if is_valid(entry)]\n",
    "    num_after = len(filtered_roidb)\n",
    "    print 'Filtered {} roidb entries: {} -> {}'.format(num - num_after,\n",
    "                                                       num, num_after)\n",
    "    return filtered_roidb\n",
    "\n",
    "\n",
    "def train_net(network, imdb, roidb, output_dir, pretrained_model=None, max_iters=40000):\n",
    "    \"\"\"Train a Fast R-CNN network.\"\"\"\n",
    "    roidb = filter_roidb(roidb)\n",
    "    saver = tf.train.Saver(max_to_keep=10)\n",
    "    with tf.Session(config=tf.ConfigProto(allow_soft_placement=True)) as sess:\n",
    "        sw = SolverWrapper(sess, saver, network, imdb, roidb, output_dir, pretrained_model=pretrained_model)\n",
    "        print 'Solving...'\n",
    "        sw.train_model(sess, max_iters)\n",
    "        print 'done solving'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
